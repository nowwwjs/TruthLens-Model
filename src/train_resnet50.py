# src/train_resnet50.py

from pathlib import Path
import time
import sys
import copy

import torch
from torch import nn, optim
from torch.utils.data import DataLoader
from torchvision import models

# --- ëª¨ë“ˆ ê²½ë¡œ ìˆ˜ì • ë¡œì§ ---
PROJECT_ROOT = Path(__file__).resolve().parents[1]
if str(PROJECT_ROOT) not in sys.path:
    sys.path.append(str(PROJECT_ROOT))

from src.dataset import FaceDataset
from .paths import WEIGHTS_DIR, PROJECT_ROOT

# ê°€ì¤‘ì¹˜ ì €ì¥ í´ë” ìƒì„±
WEIGHTS_DIR.mkdir(parents=True, exist_ok=True)

# =========================================================
# ğŸš¨ [ê²½ë¡œ ì •ì˜] ë‘ ë°ì´í„°ì…‹ì˜ CSV ë° ê°€ì¤‘ì¹˜ ê²½ë¡œ í•˜ë“œì½”ë”©
# =========================================================
INDICES_DIR = PROJECT_ROOT / "data" / "processed" / "indices"

# 1. FF++ ê²½ë¡œ (Stage 1)
FFPP_TRAIN_CSV = INDICES_DIR / "ffpp_train.csv"
FFPP_VAL_CSV = INDICES_DIR / "ffpp_val.csv"
FFPP_WEIGHTS_NAME = "ffpp_resnet50_advanced.pth"

# 2. Celeb-DF ê²½ë¡œ (Stage 2)
CELEBDF_TRAIN_CSV = INDICES_DIR / "celebdf_train.csv"
CELEBDF_VAL_CSV = INDICES_DIR / "celebdf_val.csv"
CELEBDF_WEIGHTS_NAME = "celebdf_resnet50_finetuned.pth"


# ============================================
# ë°ì´í„°ë¡œë” & ëª¨ë¸ ìœ í‹¸ë¦¬í‹°
# ============================================


def get_dataloaders(train_csv, val_csv, batch_size=64):  # ResNet50ì€ ë°°ì¹˜ 64 ê¶Œì¥
    print(f"[LOADER] Loading Train: {train_csv.name} | Val: {val_csv.name}")
    train_dataset = FaceDataset(train_csv, train=True)
    val_dataset = FaceDataset(val_csv, train=False)

    train_loader = DataLoader(
        train_dataset, batch_size=batch_size, shuffle=True, num_workers=0
    )
    val_loader = DataLoader(
        val_dataset, batch_size=batch_size, shuffle=False, num_workers=0
    )
    return train_loader, val_loader


def get_model(num_classes=2, resume_path=None, device="cpu"):
    """
    ResNet50 ëª¨ë¸ ìƒì„± (ImageNet Pretrained).
    resume_pathê°€ ìˆìœ¼ë©´ ê°€ì¤‘ì¹˜ë¥¼ ë¡œë“œí•˜ì—¬ ì´ì–´ì„œ í•™ìŠµ(Fine-tuning).
    """
    # ğŸš¨ [ìˆ˜ì •] ResNet50 ì‚¬ìš©
    model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)
    model.fc = nn.Linear(model.fc.in_features, num_classes)

    if resume_path:
        print(f"[INFO] Loading weights for Fine-tuning: {resume_path}")
        try:
            state = torch.load(resume_path, map_location=device, weights_only=True)
            model.load_state_dict(state)
            print("   -> Weights loaded successfully!")
        except FileNotFoundError:
            print(f"   -> [ERROR] Weights file not found: {resume_path}")
            return None

    return model.to(device)


def train_one_epoch(model, loader, criterion, optimizer, device):
    model.train()
    running_loss, correct, total = 0.0, 0, 0
    for images, labels in loader:
        images, labels = images.to(device), labels.to(device)
        optimizer.zero_grad()
        outputs = model(images)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        running_loss += loss.item() * images.size(0)
        _, preds = outputs.max(1)
        correct += (preds == labels).sum().item()
        total += labels.size(0)
    return running_loss / total, correct / total


def eval_one_epoch(model, loader, criterion, device):
    model.eval()
    running_loss, correct, total = 0.0, 0, 0
    with torch.no_grad():
        for images, labels in loader:
            images, labels = images.to(device), labels.to(device)
            outputs = model(images)
            loss = criterion(outputs, labels)
            running_loss += loss.item() * images.size(0)
            _, preds = outputs.max(1)
            correct += (preds == labels).sum().item()
            total += labels.size(0)
    return running_loss / total, correct / total


# ============================================
# ê°œë³„ í•™ìŠµ ì„¸ì…˜ ì‹¤í–‰ í•¨ìˆ˜
# ============================================


def run_training_session(
    session_name, train_csv, val_csv, output_name, resume_from=None, epochs=10, lr=1e-4
):
    print(f"\n{'='*20} [{session_name}] START {'='*20}")

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"[INFO] Device: {device}")

    # ë°ì´í„° ì¤€ë¹„
    try:
        train_loader, val_loader = get_dataloaders(
            train_csv, val_csv, batch_size=32
        )  # ë©”ëª¨ë¦¬ ë¶€ì¡± ì‹œ ë°°ì¹˜ ì¤„ì„
    except FileNotFoundError:
        print(f"[SKIP] CSV not found for {session_name}. Check preprocessing.")
        return None

    # ëª¨ë¸ ì¤€ë¹„
    model = get_model(resume_path=resume_from, device=device)
    if model is None:
        return None

    # ğŸš¨ [ResNet50 ì „ìš© ìµœì í™”] Label Smoothing & AdamW
    criterion = nn.CrossEntropyLoss(label_smoothing=0.1)
    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-4)

    # ìŠ¤ì¼€ì¤„ëŸ¬ ì¶”ê°€ (CosineAnnealing)
    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)

    best_acc = 0.0
    output_path = WEIGHTS_DIR / output_name

    for epoch in range(1, epochs + 1):
        start = time.time()
        t_loss, t_acc = train_one_epoch(
            model, train_loader, criterion, optimizer, device
        )
        v_loss, v_acc = eval_one_epoch(model, val_loader, criterion, device)

        scheduler.step()  # ìŠ¤ì¼€ì¤„ëŸ¬ ì—…ë°ì´íŠ¸
        elapsed = time.time() - start

        print(
            f"Epoch {epoch}/{epochs} | Train: loss={t_loss:.4f}, acc={t_acc:.4f} | Val: loss={v_loss:.4f}, acc={v_acc:.4f} | {elapsed:.1f}s"
        )

        if v_acc > best_acc:
            best_acc = v_acc
            torch.save(model.state_dict(), output_path)
            print(f"  --> Best model saved: {output_name} (acc: {best_acc:.4f})")

    print(f"{'='*20} [{session_name}] DONE {'='*20}\n")
    return output_path


# ============================================
# ë©”ì¸ íŒŒì´í”„ë¼ì¸ (ìˆœì°¨ ì‹¤í–‰)
# ============================================


def main():
    print("[PIPELINE] Starting ResNet50 2-Stage Training Pipeline...\n")

    # 1ë‹¨ê³„: FF++ í•™ìŠµ (Base Training)
    ffpp_weights = run_training_session(
        session_name="Stage 1: FF++ Base Training (ResNet50)",
        train_csv=FFPP_TRAIN_CSV,
        val_csv=FFPP_VAL_CSV,
        output_name=FFPP_WEIGHTS_NAME,
        resume_from=None,
        epochs=10,  # ResNet50ì€ ë” ê¹Šì–´ì„œ epochì„ ì¢€ ë” ëŠ˜ë¦¼
        lr=1e-4,
    )

    # 1ë‹¨ê³„ ì‹¤íŒ¨ ì‹œ ì¤‘ë‹¨
    if ffpp_weights is None or not ffpp_weights.exists():
        print("[ERROR] Stage 1 failed. Stopping pipeline.")
        return

    # 2ë‹¨ê³„: Celeb-DF í•™ìŠµ (Fine-tuning)
    run_training_session(
        session_name="Stage 2: Celeb-DF Fine-tuning (ResNet50)",
        train_csv=CELEBDF_TRAIN_CSV,
        val_csv=CELEBDF_VAL_CSV,
        output_name=CELEBDF_WEIGHTS_NAME,
        resume_from=ffpp_weights,  # 1ë‹¨ê³„ ê²°ê³¼ë¬¼ ì´ì–´ì„œ í•™ìŠµ
        epochs=5,  # Fine-tuningì€ ì ì€ epoch
        lr=1e-5,  # ë‚®ì€ í•™ìŠµë¥ 
    )

    print("[PIPELINE] All training sessions finished!")


if __name__ == "__main__":
    main()
