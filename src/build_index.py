# src/build_index.py

from pathlib import Path
import csv
import random
import argparse
from tqdm import tqdm
from sklearn.model_selection import train_test_split  # ë¶„í• ì„ ìœ„í•´ ì„¤ì¹˜ í•„ìš”

from .paths import PROJECT_ROOT

# ëœë¤ ì‹œë“œ ê³ ì • (ë¶„í•  ê²°ê³¼ì˜ ì¬í˜„ì„±ì„ ìœ„í•´)
SEED = 42
random.seed(SEED)

# ============================================
# ìœ í‹¸ í•¨ìˆ˜ 1: ë¼ë²¨ ì¶”ì¶œ (FF++ ë° Celeb-DF ëª¨ë‘ ì»¤ë²„)
# ============================================


def get_label_from_path(video_path: str) -> int:
    """
    ì˜ìƒ ê²½ë¡œë¥¼ ë¶„ì„í•˜ì—¬ ë”¥í˜ì´í¬ ë ˆì´ë¸” (0: Real, 1: Fake)ì„ ê²°ì •í•©ë‹ˆë‹¤.
    (FF++ì˜ 'original' í´ë”ëª… ë˜ëŠ” Celeb-DFì˜ 'Celeb-real' í´ë”ëª…ìœ¼ë¡œ íŒë‹¨)
    """
    p = Path(video_path)
    parts = [s.lower() for s in p.parts]

    # 'original' (FF++) ë˜ëŠ” 'celeb-real' (Celeb-DF)ì´ í¬í•¨ë˜ë©´ Real (0)
    if "original" in parts or "celeb-real" in parts or "youtube-real" in parts:
        return 0  # Real

    # 'Deepfakes', 'FaceSwap', 'Celeb-synthesis' ë“±ì´ í¬í•¨ë˜ë©´ Fake (1)
    return 1  # Fake


def group_by_video(faces_rows):
    """ì–¼êµ´ í–‰ë“¤ì„ ì˜ìƒ ë‹¨ìœ„ë¡œ ê·¸ë£¹í™”í•©ë‹ˆë‹¤."""
    by_video = {}

    for row in faces_rows:
        video_path = row["video_path"]

        if video_path not in by_video:
            # get_label_from_path í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•´ ë¼ë²¨ì„ ê²°ì •
            label = get_label_from_path(video_path)
            by_video[video_path] = {"label": label, "rows": []}

        by_video[video_path]["rows"].append(row)

    return by_video


# ============================================
# ìœ í‹¸ í•¨ìˆ˜ 2: ì˜ìƒ ë‹¨ìœ„ ë¶„í•  (80:10:10)
# ============================================


def split_videos(video_paths, train_ratio=0.8, val_ratio=0.1):
    """ì˜ìƒ ë‹¨ìœ„ë¡œ train / val / test ë¶„í•  (Stratify ì—†ì´ ë‹¨ìˆœ ëœë¤ ë¶„í• )"""

    video_paths = list(video_paths)

    # scikit-learnì˜ train_test_splitì„ ì‚¬ìš©í•˜ì—¬ ë¶„í• 
    # 1ì°¨ ë¶„ë¦¬: Test set ë¶„ë¦¬
    train_val_v, test_v = train_test_split(
        video_paths, test_size=val_ratio, random_state=SEED
    )

    # 2ì°¨ ë¶„ë¦¬: Train setê³¼ Validation set ë¶„ë¦¬
    val_size = val_ratio / (train_ratio + val_ratio)  # ì˜ˆ: 0.1 / 0.9 = 0.111...
    train_v, val_v = train_test_split(
        train_val_v, test_size=val_size, random_state=SEED
    )

    return set(train_v), set(val_v), set(test_v)


def write_csv(path: Path, rows, fieldnames):
    """ì£¼ì–´ì§„ rows ë¦¬ìŠ¤íŠ¸ë¥¼ path ìœ„ì¹˜ì˜ CSV íŒŒì¼ë¡œ ì €ì¥"""

    if not rows:
        return

    path.parent.mkdir(parents=True, exist_ok=True)

    with path.open("w", newline="", encoding="utf-8") as f:
        writer = csv.DictWriter(f, fieldnames=fieldnames)
        writer.writeheader()
        writer.writerows(rows)


# ============================================
# ë©”ì¸ ì²˜ë¦¬ ë¡œì§
# ============================================


def run_indexing(input_csv, output_prefix):

    FACES_CSV = Path(input_csv)
    OUTPUT_PREFIX = Path(output_prefix)

    # 1. faces_csv ì½ê¸° (ì´ì „ì— extract_faces.pyê°€ ìƒì„±í•œ CSV)
    faces_rows = []
    with FACES_CSV.open("r", encoding="utf-8") as f:
        reader = csv.DictReader(f)
        for row in tqdm(reader, desc=f"Loading faces from {FACES_CSV.name}"):
            faces_rows.append(row)

    print(f"[INFO] Loaded {len(faces_rows)} face rows")

    # 2. ì˜ìƒë‹¨ìœ„ë¡œ ê·¸ë£¹í™” ë° ë¶„í• 
    by_video = group_by_video(faces_rows)
    video_paths = list(by_video.keys())

    train_v, val_v, test_v = split_videos(video_paths)

    # 3. ê° rowì— ë¼ë²¨ ë° split ì •ë³´ ì¶”ê°€
    all_rows = []
    train_rows, val_rows, test_rows = [], [], []

    for video_path, info in by_video.items():
        # ... (split ì •ë³´ ì¶”ê°€ ë° row í• ë‹¹ ë¡œì§ì€ ìœ ì§€) ...

        if video_path in train_v:
            split = "train"
            target_list = train_rows
        elif video_path in val_v:
            split = "val"
            target_list = val_rows
        else:
            split = "test"
            target_list = test_rows

        for row in info["rows"]:
            new_row = dict(row)
            new_row["label"] = info[
                "label"
            ]  # ì´ë¯¸ get_label_from_pathì—ì„œ ì •í•´ì§„ ë¼ë²¨ ì‚¬ìš©
            new_row["split"] = split

            all_rows.append(new_row)
            target_list.append(new_row)

    # 4. CSV ì €ì¥
    fieldnames = (
        list(all_rows[0].keys())
        if all_rows
        else ["video_path", "frame_path", "face_path", "label", "split"]
    )

    write_csv(
        OUTPUT_PREFIX.parent / (OUTPUT_PREFIX.name + "_all.csv"), all_rows, fieldnames
    )
    write_csv(
        OUTPUT_PREFIX.parent / (OUTPUT_PREFIX.name + "_train.csv"),
        train_rows,
        fieldnames,
    )
    write_csv(
        OUTPUT_PREFIX.parent / (OUTPUT_PREFIX.name + "_val.csv"), val_rows, fieldnames
    )
    write_csv(
        OUTPUT_PREFIX.parent / (OUTPUT_PREFIX.name + "_test.csv"), test_rows, fieldnames
    )

    print(
        f"[DONE] Saved indices. Train: {len(train_rows)}, Val: {len(val_rows)}, Test: {len(test_rows)}"
    )


def main():
    # ğŸš¨ [ì¶”ê°€] ëª…ë ¹ì¤„ ì¸ìë¥¼ ì²˜ë¦¬í•˜ëŠ” ë¡œì§
    parser = argparse.ArgumentParser(
        description="Creates train/val/test splits at the video level for any dataset."
    )
    # ì¸ì ì •ì˜
    parser.add_argument(
        "--input-csv",
        type=str,
        required=True,
        help="Input CSV containing cropped face paths (e.g., data/processed/indices/faces_ffpp.csv)",
    )
    parser.add_argument(
        "--output-prefix",
        type=str,
        required=True,
        help="Base path and prefix for output CSVs (e.g., data/processed/indices/ffpp)",
    )

    args = parser.parse_args()

    # run_indexing í•¨ìˆ˜ í˜¸ì¶œ
    run_indexing(args.input_csv, args.output_prefix)


if __name__ == "__main__":
    main()
